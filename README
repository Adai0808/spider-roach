crawl
控制爬虫运行的入口，以后可以修改成读取命令参数，即可执行对应不同的爬虫策略。
scheduler.py
定义自己的爬虫,实现爬虫的调度算法，并将pipeline中负责解析的类注册到爬虫中：
继承BaseSpider基类即可实现一个自己的爬虫，然后重写 Rules函数，定义自己的爬行策略。

msp.cfg
配置待抓取页面相应的抽取规则

运行程序：
./crawl spider -d(可选)

目前实现功能：
1.多线程下载,线程数可配置
2.根据配置自动抽取页面
3.根据配置构造SQL语句执行
4.可自定
5.

待实现的功能：
1.与Redis交互数据
2.具体的调度策略
3.增量策略
4.

